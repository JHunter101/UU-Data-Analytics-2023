{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project by:\n",
    "- Jack Chen 4427737\n",
    "- Joost Litjes 4540700\n",
    "- Felicia Hung 7568479"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "import sklearn\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import plotly.express as px \n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.defaults.width = 600\n",
    "px.defaults.height = 600"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>months_since_last_donation</th>\n",
       "      <th>total_number_of_donations</th>\n",
       "      <th>total_blood_donated</th>\n",
       "      <th>months_since_first_donation</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>748.000000</td>\n",
       "      <td>748.000000</td>\n",
       "      <td>748.000000</td>\n",
       "      <td>748.000000</td>\n",
       "      <td>748.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.506684</td>\n",
       "      <td>5.514706</td>\n",
       "      <td>1378.676471</td>\n",
       "      <td>34.282086</td>\n",
       "      <td>0.237968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.095396</td>\n",
       "      <td>5.839307</td>\n",
       "      <td>1459.826781</td>\n",
       "      <td>24.376714</td>\n",
       "      <td>0.426124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1750.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>74.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>12500.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       months_since_last_donation  total_number_of_donations  \\\n",
       "count                  748.000000                 748.000000   \n",
       "mean                     9.506684                   5.514706   \n",
       "std                      8.095396                   5.839307   \n",
       "min                      0.000000                   1.000000   \n",
       "25%                      2.750000                   2.000000   \n",
       "50%                      7.000000                   4.000000   \n",
       "75%                     14.000000                   7.000000   \n",
       "max                     74.000000                  50.000000   \n",
       "\n",
       "       total_blood_donated  months_since_first_donation       class  \n",
       "count           748.000000                   748.000000  748.000000  \n",
       "mean           1378.676471                    34.282086    0.237968  \n",
       "std            1459.826781                    24.376714    0.426124  \n",
       "min             250.000000                     2.000000    0.000000  \n",
       "25%             500.000000                    16.000000    0.000000  \n",
       "50%            1000.000000                    28.000000    0.000000  \n",
       "75%            1750.000000                    50.000000    0.000000  \n",
       "max           12500.000000                    98.000000    1.000000  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = pd.read_csv(\"blood_transfusion.csv\")\n",
    "db.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\n",
    "    \"months_since_last_donation\",\n",
    "    \"total_number_of_donations\",\n",
    "    \"total_blood_donated\",\n",
    "    \"months_since_first_donation\",\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    \"class\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportImage(plot, name):\n",
    "    pio.write_html(plot, os.path.join(\"plots\", name + '.html'))\n",
    "    \n",
    "    # Change if you want to print plots !!\n",
    "    # fig.show()\n",
    "\n",
    "# Manual normalization function\n",
    "def normalize_column(column):\n",
    "    min_val = column.min()\n",
    "    max_val = column.max()\n",
    "    return (column - min_val) / (max_val - min_val)\n",
    "\n",
    "for column in numeric_features:\n",
    "    db[column] = normalize_column(db[column])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = db.astype({col: str for col in db.columns if col in categorical_features})\n",
    "\n",
    "for column in numeric_features:\n",
    "    db[column] = normalize_column(db[column])\n",
    "\n",
    "class_0_df = db[db['class'] == \"0\"]\n",
    "class_1_df = db[db['class'] == \"1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "for i, column in enumerate(numeric_features):\n",
    "    fig.add_trace(\n",
    "        go.Box(x=db['class'], \n",
    "        y=db[column], \n",
    "        name=column),\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    boxmode='group',\n",
    "    width=len(numeric_features)*200, height=400, title_text=\"Comparing trends between class 0 and class 1 for Numeric Features\")\n",
    "exportImage(fig, \"Comparing trends between class 0 and class 1 for Numeric Features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    " for df_name, data in zip([\"class 0\", \"class 1\"], [class_0_df, class_1_df]):\n",
    "    fig = make_subplots(rows=len(numeric_features), cols=len(numeric_features))\n",
    "\n",
    "    for i, feature_to_plot_y in enumerate(numeric_features):\n",
    "        for j, feature_to_plot_x in enumerate(numeric_features):\n",
    "            trace = go.Scatter(x=data[feature_to_plot_x], y=data[feature_to_plot_y], text=\"\", mode='markers', showlegend=False)\n",
    "            fig.add_trace(trace, row=j+1, col=i+1)\n",
    "\n",
    "    # Add x and y labels to the subplots\n",
    "    for i, feature in enumerate(numeric_features):\n",
    "        fig.update_xaxes(title_text=feature, row=len(numeric_features), col=i+1)\n",
    "        fig.update_yaxes(title_text=feature, row=i+1, col=1)\n",
    "\n",
    "    fig.update_layout(height=len(numeric_features)*250, width=len(numeric_features)*250, title_text=f\"Comparing feature relations with {df_name}\")\n",
    "    exportImage(fig, f\"Comparing feature relations with {df_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical features to numerical using one-hot encoding\n",
    "data_encoded = pd.get_dummies(db, columns=['class'], drop_first=False)\n",
    "\n",
    "# Calculate the correlation matrix for dummified categorical features\n",
    "correlation_matrix_categorical = list(data_encoded[\n",
    "    data_encoded.columns.difference(numeric_features)\n",
    "].columns)\n",
    "\n",
    "correlation_matrix = data_encoded[numeric_features + correlation_matrix_categorical].corr()\n",
    "\n",
    "numeric_features_indexes = [correlation_matrix.columns.get_loc(col) for col in numeric_features]\n",
    "categorical_features_indexes = [correlation_matrix.columns.get_loc(col) for col in correlation_matrix_categorical]\n",
    "\n",
    "data = correlation_matrix.iloc[numeric_features_indexes, numeric_features_indexes]\n",
    "fig = px.imshow(\n",
    "    data,\n",
    "    labels=dict(x=\"Numeric Features\", y=\"Numeric Features\", color=\"Correlation\"),\n",
    "    title=\"Correlation Heatmap of Numerical Features\",\n",
    ")\n",
    "exportImage(fig, \"Correlation Heatmap of Numerical Features\")\n",
    "\n",
    "data = correlation_matrix.iloc[numeric_features_indexes, categorical_features_indexes]\n",
    "fig = px.imshow(\n",
    "    data,\n",
    "    labels=dict(x=\"Numeric Features\", y=\"Categorical Features\", color=\"Correlation\"),\n",
    "    title=\"Correlation Heatmap of Numerical vs Categorical Features\",\n",
    ")\n",
    "exportImage(fig, \"Correlation Heatmap of Numerical vs Categorical Features\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data(db, train_features, label_feature, test_size, seed = 101):\n",
    "    return train_test_split(db[train_features].to_numpy(), db[label_feature].to_numpy(), test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNNClassifier:\n",
    "    def __init__(self, k=3):\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "    def euclidean_distance(self, x1, x2):\n",
    "        return np.linalg.norm(x1 - x2)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Make predictions for an array of data points X\n",
    "        y_pred = []\n",
    "\n",
    "        for x in X:\n",
    "            distances = []\n",
    "\n",
    "            for i in range(len(self.X_train)):\n",
    "                distance = self.euclidean_distance(x, self.X_train[i])\n",
    "                distances.append((distance, self.y_train[i]))\n",
    "\n",
    "            # Sort the distances and select the k-nearest neighbors\n",
    "            distances.sort(key=lambda x: x[0])\n",
    "            neighbors = distances[:self.k]\n",
    "\n",
    "            # Count the votes from the k-nearest neighbors\n",
    "            class_votes = {}\n",
    "            for neighbor in neighbors:\n",
    "                label = neighbor[1]\n",
    "                if label in class_votes:\n",
    "                    class_votes[label] += 1\n",
    "                else:\n",
    "                    class_votes[label] = 1\n",
    "\n",
    "            # Return the class with the most votes as the prediction\n",
    "            predicted_class = max(class_votes, key=class_votes.get)\n",
    "            y_pred.append(predicted_class)\n",
    "\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(y_true, y_pred):\n",
    "    TP = TN = FP = FN = 0\n",
    "    for true, pred in zip(y_true, y_pred):\n",
    "        true = int(true)\n",
    "        pred = int(pred)\n",
    "        if true == 1:\n",
    "            if pred == 1:\n",
    "                TP += 1\n",
    "            else:\n",
    "                FN += 1\n",
    "        else:\n",
    "            if pred == 1:\n",
    "                FP += 1\n",
    "            else:\n",
    "                TN += 1\n",
    "\n",
    "    return {\n",
    "        \"TP\": TP,\n",
    "        \"TN\": TN,\n",
    "        \"FP\": FP,\n",
    "        \"FN\": FN\n",
    "    }\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import random\n",
    "\n",
    "def classifierTests(db, numeric_features, classifiers, label_feature, test_sizes):\n",
    "    results = {}\n",
    "    for n in test_sizes:\n",
    "        # Split the alternative dataset\n",
    "        seed = random.randint(0,101)\n",
    "        X_train, X_test, y_train, y_test = split_data(db, numeric_features, \"class\", n, seed)\n",
    "\n",
    "        for classifier in classifiers:\n",
    "            # Train the classifier on the main dataset\n",
    "            classifier.fit(X_train, y_train)\n",
    "\n",
    "            # Predict on the alternative dataset\n",
    "            y_pred = classifier.predict(X_test)\n",
    "\n",
    "            # Compare the predicted labels with the actual labels\n",
    "            conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "            class_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "            fbeta = fbeta_score(y_test, y_pred, average='macro', beta=0.5)\n",
    "\n",
    "            if classifier.__class__.__name__ not in results:\n",
    "                results[classifier.__class__.__name__] = [] \n",
    "            \n",
    "            results[classifier.__class__.__name__].append({\n",
    "                'Classifier': classifier.__class__.__name__,\n",
    "                'Test Size': n,\n",
    "                'Confusion Matrix': conf_matrix,\n",
    "                'Classification Report': class_report,\n",
    "                'F-Beta Score': fbeta,\n",
    "            })\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\tools\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "c:\\tools\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "c:\\tools\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "c:\\tools\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "c:\\tools\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "c:\\tools\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "c:\\tools\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "c:\\tools\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "c:\\tools\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "c:\\tools\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "c:\\tools\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "c:\\tools\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "c:\\tools\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "c:\\tools\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "c:\\tools\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Define the list of classifiers\n",
    "\n",
    "classifiers = [\n",
    "    KNNClassifier(),\n",
    "    GaussianNB(),\n",
    "    SVC(kernel='linear', random_state=101),\n",
    "    MLPClassifier(hidden_layer_sizes=(100, 100), max_iter=1000),\n",
    "    ]\n",
    "\n",
    "test_sizes = [\n",
    "        0.15,\n",
    "        0.35, \n",
    "        0.50, \n",
    "        0.65, \n",
    "        0.85\n",
    "        ]\n",
    "\n",
    "results = classifierTests(db, numeric_features, classifiers, \"class\", test_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def classifierTests(db, numeric_features, classifiers, label_feature, n_splits):\n",
    "    results = {}\n",
    "    \n",
    "    kf = KFold(n_splits=n_splits, random_state=None, shuffle=False)\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(db[numeric_features])):\n",
    "        X_train, X_test = db[numeric_features].iloc[train_index].to_numpy(), db[numeric_features].iloc[test_index].to_numpy()\n",
    "        y_train, y_test = db[label_feature].iloc[train_index].to_numpy(), db[label_feature].iloc[test_index].to_numpy()\n",
    "\n",
    "        for classifier in classifiers:\n",
    "            classifier.fit(X_train, y_train)\n",
    "            y_pred = classifier.predict(X_test)\n",
    "\n",
    "            conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "            class_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "            fbeta = fbeta_score(y_test, y_pred, average='macro', beta=0.5)\n",
    "            \n",
    "            if classifier.__class__.__name__ not in results:\n",
    "                results[classifier.__class__.__name__] = []\n",
    "\n",
    "            attributes = {}\n",
    "            for attr_name, attr_value in inspect.getmembers(classifier):\n",
    "                if isinstance(attr_value, (int, float, str)):\n",
    "                    if attr_name != \"__module__\":\n",
    "                        attributes[attr_name] = attr_value\n",
    "            \n",
    "            results[classifier.__class__.__name__].append({\n",
    "                'classifier': classifier.__class__.__name__,\n",
    "                'fold': i,\n",
    "                'parameters': attributes,\n",
    "                'confusion_matrix': conf_matrix,\n",
    "                'classification_report': class_report,\n",
    "                'f_beta_score': fbeta,\n",
    "            })\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jackc\\AppData\\Local\\Temp\\ipykernel_263296\\1198442449.py:11: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>fold</th>\n",
       "      <th>f_beta_score</th>\n",
       "      <th>parameters_k</th>\n",
       "      <th>confusion_matrix_TP</th>\n",
       "      <th>confusion_matrix_TN</th>\n",
       "      <th>confusion_matrix_FP</th>\n",
       "      <th>confusion_matrix_FN</th>\n",
       "      <th>classification_report_0_precision</th>\n",
       "      <th>classification_report_0_recall</th>\n",
       "      <th>...</th>\n",
       "      <th>classification_report_1_support</th>\n",
       "      <th>classification_report_accuracy</th>\n",
       "      <th>classification_report_macro avg_precision</th>\n",
       "      <th>classification_report_macro avg_recall</th>\n",
       "      <th>classification_report_macro avg_f1-score</th>\n",
       "      <th>classification_report_macro avg_support</th>\n",
       "      <th>classification_report_weighted avg_precision</th>\n",
       "      <th>classification_report_weighted avg_recall</th>\n",
       "      <th>classification_report_weighted avg_f1-score</th>\n",
       "      <th>classification_report_weighted avg_support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNNClassifier</td>\n",
       "      <td>0</td>\n",
       "      <td>0.550390</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>63</td>\n",
       "      <td>48</td>\n",
       "      <td>35</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.567568</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>0.556150</td>\n",
       "      <td>0.551766</td>\n",
       "      <td>0.553521</td>\n",
       "      <td>0.549920</td>\n",
       "      <td>187</td>\n",
       "      <td>0.568815</td>\n",
       "      <td>0.556150</td>\n",
       "      <td>0.559831</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNNClassifier</td>\n",
       "      <td>0</td>\n",
       "      <td>0.562986</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>67</td>\n",
       "      <td>44</td>\n",
       "      <td>36</td>\n",
       "      <td>0.650485</td>\n",
       "      <td>0.603604</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>0.572193</td>\n",
       "      <td>0.563338</td>\n",
       "      <td>0.564960</td>\n",
       "      <td>0.563084</td>\n",
       "      <td>187</td>\n",
       "      <td>0.579649</td>\n",
       "      <td>0.572193</td>\n",
       "      <td>0.574891</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNNClassifier</td>\n",
       "      <td>0</td>\n",
       "      <td>0.548961</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>64</td>\n",
       "      <td>47</td>\n",
       "      <td>36</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.576577</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>0.556150</td>\n",
       "      <td>0.549885</td>\n",
       "      <td>0.551446</td>\n",
       "      <td>0.548716</td>\n",
       "      <td>187</td>\n",
       "      <td>0.566751</td>\n",
       "      <td>0.556150</td>\n",
       "      <td>0.559557</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNNClassifier</td>\n",
       "      <td>0</td>\n",
       "      <td>0.591727</td>\n",
       "      <td>5</td>\n",
       "      <td>37</td>\n",
       "      <td>77</td>\n",
       "      <td>34</td>\n",
       "      <td>39</td>\n",
       "      <td>0.663793</td>\n",
       "      <td>0.693694</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>0.609626</td>\n",
       "      <td>0.592460</td>\n",
       "      <td>0.590268</td>\n",
       "      <td>0.590908</td>\n",
       "      <td>187</td>\n",
       "      <td>0.605811</td>\n",
       "      <td>0.609626</td>\n",
       "      <td>0.607286</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNNClassifier</td>\n",
       "      <td>0</td>\n",
       "      <td>0.603019</td>\n",
       "      <td>6</td>\n",
       "      <td>38</td>\n",
       "      <td>78</td>\n",
       "      <td>33</td>\n",
       "      <td>38</td>\n",
       "      <td>0.672414</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>0.620321</td>\n",
       "      <td>0.603813</td>\n",
       "      <td>0.601351</td>\n",
       "      <td>0.602116</td>\n",
       "      <td>187</td>\n",
       "      <td>0.616652</td>\n",
       "      <td>0.620321</td>\n",
       "      <td>0.618045</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      classifier  fold  f_beta_score  parameters_k  confusion_matrix_TP  \\\n",
       "0  KNNClassifier     0      0.550390             2                   41   \n",
       "1  KNNClassifier     0      0.562986             3                   40   \n",
       "2  KNNClassifier     0      0.548961             4                   40   \n",
       "3  KNNClassifier     0      0.591727             5                   37   \n",
       "4  KNNClassifier     0      0.603019             6                   38   \n",
       "\n",
       "   confusion_matrix_TN  confusion_matrix_FP  confusion_matrix_FN  \\\n",
       "0                   63                   48                   35   \n",
       "1                   67                   44                   36   \n",
       "2                   64                   47                   36   \n",
       "3                   77                   34                   39   \n",
       "4                   78                   33                   38   \n",
       "\n",
       "   classification_report_0_precision  classification_report_0_recall  ...  \\\n",
       "0                           0.642857                        0.567568  ...   \n",
       "1                           0.650485                        0.603604  ...   \n",
       "2                           0.640000                        0.576577  ...   \n",
       "3                           0.663793                        0.693694  ...   \n",
       "4                           0.672414                        0.702703  ...   \n",
       "\n",
       "   classification_report_1_support  classification_report_accuracy  \\\n",
       "0                               76                        0.556150   \n",
       "1                               76                        0.572193   \n",
       "2                               76                        0.556150   \n",
       "3                               76                        0.609626   \n",
       "4                               76                        0.620321   \n",
       "\n",
       "   classification_report_macro avg_precision  \\\n",
       "0                                   0.551766   \n",
       "1                                   0.563338   \n",
       "2                                   0.549885   \n",
       "3                                   0.592460   \n",
       "4                                   0.603813   \n",
       "\n",
       "   classification_report_macro avg_recall  \\\n",
       "0                                0.553521   \n",
       "1                                0.564960   \n",
       "2                                0.551446   \n",
       "3                                0.590268   \n",
       "4                                0.601351   \n",
       "\n",
       "   classification_report_macro avg_f1-score  \\\n",
       "0                                  0.549920   \n",
       "1                                  0.563084   \n",
       "2                                  0.548716   \n",
       "3                                  0.590908   \n",
       "4                                  0.602116   \n",
       "\n",
       "   classification_report_macro avg_support  \\\n",
       "0                                      187   \n",
       "1                                      187   \n",
       "2                                      187   \n",
       "3                                      187   \n",
       "4                                      187   \n",
       "\n",
       "   classification_report_weighted avg_precision  \\\n",
       "0                                      0.568815   \n",
       "1                                      0.579649   \n",
       "2                                      0.566751   \n",
       "3                                      0.605811   \n",
       "4                                      0.616652   \n",
       "\n",
       "   classification_report_weighted avg_recall  \\\n",
       "0                                   0.556150   \n",
       "1                                   0.572193   \n",
       "2                                   0.556150   \n",
       "3                                   0.609626   \n",
       "4                                   0.620321   \n",
       "\n",
       "   classification_report_weighted avg_f1-score  \\\n",
       "0                                     0.559831   \n",
       "1                                     0.574891   \n",
       "2                                     0.559557   \n",
       "3                                     0.607286   \n",
       "4                                     0.618045   \n",
       "\n",
       "   classification_report_weighted avg_support  \n",
       "0                                         187  \n",
       "1                                         187  \n",
       "2                                         187  \n",
       "3                                         187  \n",
       "4                                         187  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifiers = [\n",
    "    ]\n",
    "\n",
    "for k in range(2,7):\n",
    "    classifiers.append(KNNClassifier(k))\n",
    "\n",
    "results = classifierTests(db, numeric_features, classifiers, \"class\", 4)\n",
    "result_df = pd.DataFrame()\n",
    "for key in results:\n",
    "    flattened_df = pd.json_normalize(results[key], sep='_')\n",
    "    result_df = result_df.append(flattened_df, ignore_index=True)\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_groups = [\n",
    "    [\n",
    "        'confusion_matrix_TP',\n",
    "        'confusion_matrix_TN',\n",
    "        'confusion_matrix_FP',\n",
    "        'confusion_matrix_FN',\n",
    "    ],\n",
    "    [\n",
    "        'classification_report_0_precision',\n",
    "        'classification_report_0_recall',\n",
    "        'classification_report_0_f1-score',\n",
    "        'classification_report_1_precision',\n",
    "        'classification_report_1_recall',\n",
    "        'classification_report_1_f1-score',\n",
    "        'f_beta_score',\n",
    "    ],\n",
    "    [\n",
    "        'classification_report_accuracy',\n",
    "        'classification_report_macro avg_precision',\n",
    "        'classification_report_macro avg_recall',\n",
    "        'classification_report_macro avg_f1-score',\n",
    "        'classification_report_weighted avg_precision',\n",
    "        'classification_report_weighted avg_recall',\n",
    "        'classification_report_weighted avg_f1-score',\n",
    "        'f_beta_score',\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = result_df.groupby('parameters_k').mean().reset_index()\n",
    "for yList in score_groups:\n",
    "    fig = px.line(result_df, x='parameters_k', y=yList,\n",
    "                markers=True, title='Scores by Parameters K',\n",
    "                labels={'value': 'Score'})\n",
    "    exportImage(fig, f'Scores by Parameters K {yList[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jackc\\AppData\\Local\\Temp\\ipykernel_263296\\3604445725.py:5: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = classifierTests(db, numeric_features, [KNNClassifier(k=3)], \"class\", 4)\n",
    "result_df = pd.DataFrame()\n",
    "for key in results:\n",
    "    flattened_df = pd.json_normalize(results[key], sep='_')\n",
    "    result_df = result_df.append(flattened_df, ignore_index=True)\n",
    "\n",
    "result_df = result_df.groupby('fold').mean().reset_index()\n",
    "for yList in score_groups:\n",
    "    fig = px.line(result_df, x='fold', y=yList,\n",
    "                markers=True, title='Scores by Fold',\n",
    "                labels={'value': 'Score'})\n",
    "    exportImage(fig, f'Scores by Fold {yList[0]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
