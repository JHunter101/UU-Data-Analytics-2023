import math

class KNNClassifier:
    def __init__(self, k=3):
        self.k = k
        self.train_data = None
        self.train_labels = None

    def euclidean_distance(self, point1, point2):
        distance = 0
        for i in range(len(point1)):
            distance += (point1[i] - point2[i]) ** 2
        return math.sqrt(distance)

    def fit(self, X, y):
        self.train_data = X
        self.train_labels = y

    def predict(self, test_point):
        if self.train_data is None or self.train_labels is None:
            raise ValueError("Fit the model with training data before making predictions")

        # Create a list to store the distances and corresponding labels
        distances = []
        for i in range(len(self.train_data)):
            dist = self.euclidean_distance(self.train_data[i], test_point)
            distances.append((dist, self.train_labels[i]))

        # Sort the distances in ascending order and take the first 'k' elements
        distances.sort(key=lambda x: x[0])
        nearest_neighbors = distances[:self.k]

        # Count the occurrences of each class in the 'k' nearest neighbors
        class_count = {}
        for neighbor in nearest_neighbors:
            _, label = neighbor
            if label in class_count:
                class_count[label] += 1
            else:
                class_count[label] = 1

        # Find the class with the highest count
        predicted_class = max(class_count, key=class_count.get)

        return predicted_class

# Example usage
if __name__ == "__main__":
    # Create a KNN classifier with k=3
    knn = KNNClassifier(k=3)

    # Sample training data and labels
    X_train = [(1, 2), (2, 3), (3, 3), (2, 1), (3, 2)]
    y_train = ["A", "A", "B", "B", "A"]

    # Fit the classifier with training data
    knn.fit(X_train, y_train)

    # Test point
    test_point = (2.5, 2.5)

    # Use the KNN classifier to predict the class of the test point
    predicted_class = knn.predict(test_point)
    print("Predicted class:", predicted_class)
